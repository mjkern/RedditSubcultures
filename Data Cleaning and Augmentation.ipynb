{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Augmentation\n",
    "This notebook is meant to read in the data downloaded from reddit and prepare it for analysis by cleaning it and doing some computation...\n",
    "\n",
    "But is has become my whole analysis - sorry..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to analyze something else\n",
    "\n",
    "# ## a big one:\n",
    "# subreddit = \"enlightenedbirdmen\"\n",
    "# download_date_string = \"19.12.04-14:27:14\"\n",
    "\n",
    "# ## a meduim one:\n",
    "# subreddit = \"justwriterthings\"\n",
    "# download_date_string = \"19.12.04-10:30:56\"\n",
    "\n",
    "# ## a small one:\n",
    "# subreddit = \"The_B_Emoji\"\n",
    "# download_date_string = \"19.12.04-09:28:30\"\n",
    "\n",
    "# ## a very small one:\n",
    "# subreddit = \"GamesWithHorses\"\n",
    "# download_date_string = \"19.12.04-10:33:02\"\n",
    "\n",
    "# subreddit = \"relationship_advice\"\n",
    "# download_date_string = \"19.12.05-20:17:26\"\n",
    "\n",
    "# subreddit = \"Showerthoughts\"\n",
    "# download_date_string = \"19.12.05-20:40:00\"\n",
    "\n",
    "subreddit = \"todayilearned\"\n",
    "download_date_string = \"19.12.05-19:38:34\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_directory = \"downloads/\"\n",
    "submissions_suffix = \"-submissions-\" + download_date_string + \".csv\"\n",
    "comments_suffix = \"-comments-\" + download_date_string + \".csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission_id</th>\n",
       "      <th>user</th>\n",
       "      <th>utc</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e6qdg8</td>\n",
       "      <td>purplealienandproud</td>\n",
       "      <td>1.575591e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>TIL Religious groups in America normally have ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>todayilearned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e6qcx9</td>\n",
       "      <td>SamWilber</td>\n",
       "      <td>1.575591e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>TIL an oil change for a Lamborghini costs over...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>todayilearned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e6q587</td>\n",
       "      <td>CanuckBacon</td>\n",
       "      <td>1.575590e+09</td>\n",
       "      <td>12</td>\n",
       "      <td>TIL that when considering what to name Idaho, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>todayilearned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e6q3qk</td>\n",
       "      <td>ResidentDoctorEvil</td>\n",
       "      <td>1.575590e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>TIL the practice of family restaurants seating...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>todayilearned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e6q1fd</td>\n",
       "      <td>Randomosaur</td>\n",
       "      <td>1.575590e+09</td>\n",
       "      <td>8</td>\n",
       "      <td>TIL spotted hyenas are able to digest all orga...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>todayilearned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  submission_id                 user           utc  score  \\\n",
       "0        e6qdg8  purplealienandproud  1.575591e+09      4   \n",
       "1        e6qcx9            SamWilber  1.575591e+09      1   \n",
       "2        e6q587          CanuckBacon  1.575590e+09     12   \n",
       "3        e6q3qk   ResidentDoctorEvil  1.575590e+09      6   \n",
       "4        e6q1fd          Randomosaur  1.575590e+09      8   \n",
       "\n",
       "                                               title  body      subreddit  \n",
       "0  TIL Religious groups in America normally have ...   NaN  todayilearned  \n",
       "1  TIL an oil change for a Lamborghini costs over...   NaN  todayilearned  \n",
       "2  TIL that when considering what to name Idaho, ...   NaN  todayilearned  \n",
       "3  TIL the practice of family restaurants seating...   NaN  todayilearned  \n",
       "4  TIL spotted hyenas are able to digest all orga...   NaN  todayilearned  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the submissions\n",
    "submissions_file = data_directory + subreddit + submissions_suffix\n",
    "submissions = pd.read_csv(submissions_file, index_col=0)\n",
    "submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>user</th>\n",
       "      <th>utc</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f9sfnw5</td>\n",
       "      <td>t3_e6qdg8</td>\n",
       "      <td>leadchipmunk</td>\n",
       "      <td>1.575592e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>Yo, who wants some popcorn? This is going to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9sfrk9</td>\n",
       "      <td>t3_e6qdg8</td>\n",
       "      <td>Noctis_Raptor</td>\n",
       "      <td>1.575592e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NERD FIGHT!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f9sfnu8</td>\n",
       "      <td>t3_e6qcx9</td>\n",
       "      <td>Noctis_Raptor</td>\n",
       "      <td>1.575592e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>To someone who can comfortably afford a Lambor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f9sf6jl</td>\n",
       "      <td>t3_e6q587</td>\n",
       "      <td>textoen</td>\n",
       "      <td>1.575591e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it was short for Idunno? What shall ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f9sf6k4</td>\n",
       "      <td>t3_e6q587</td>\n",
       "      <td>Populistless</td>\n",
       "      <td>1.575591e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>No you da ho!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id submission_id           user           utc  score  \\\n",
       "0    f9sfnw5     t3_e6qdg8   leadchipmunk  1.575592e+09      1   \n",
       "1    f9sfrk9     t3_e6qdg8  Noctis_Raptor  1.575592e+09      1   \n",
       "2    f9sfnu8     t3_e6qcx9  Noctis_Raptor  1.575592e+09      1   \n",
       "3    f9sf6jl     t3_e6q587        textoen  1.575591e+09      1   \n",
       "4    f9sf6k4     t3_e6q587   Populistless  1.575591e+09      1   \n",
       "\n",
       "                                                body  \n",
       "0  Yo, who wants some popcorn? This is going to g...  \n",
       "1                                        NERD FIGHT!  \n",
       "2  To someone who can comfortably afford a Lambor...  \n",
       "3  I thought it was short for Idunno? What shall ...  \n",
       "4                                      No you da ho!  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the comments\n",
    "comments_file = data_directory + subreddit + comments_suffix\n",
    "comments = pd.read_csv(comments_file, index_col=0)\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the t3_ prefix from comment submission ids\n",
    "comments[\"submission_id\"] = comments[\"submission_id\"].apply(lambda s: s.split(\"t3_\")[1])\n",
    "\n",
    "# Empty content should be the empty string - not nan\n",
    "submissions['body'] = submissions['body'].fillna(value=\"\")\n",
    "comments['body'] = comments['body'].fillna(value=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>user</th>\n",
       "      <th>utc</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f9sfnw5</td>\n",
       "      <td>e6qdg8</td>\n",
       "      <td>leadchipmunk</td>\n",
       "      <td>1.575592e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>Yo, who wants some popcorn? This is going to g...</td>\n",
       "      <td>2019-12-06 00:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f9sfrk9</td>\n",
       "      <td>e6qdg8</td>\n",
       "      <td>Noctis_Raptor</td>\n",
       "      <td>1.575592e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NERD FIGHT!</td>\n",
       "      <td>2019-12-06 00:19:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f9sfnu8</td>\n",
       "      <td>e6qcx9</td>\n",
       "      <td>Noctis_Raptor</td>\n",
       "      <td>1.575592e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>To someone who can comfortably afford a Lambor...</td>\n",
       "      <td>2019-12-06 00:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f9sf6jl</td>\n",
       "      <td>e6q587</td>\n",
       "      <td>textoen</td>\n",
       "      <td>1.575591e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it was short for Idunno? What shall ...</td>\n",
       "      <td>2019-12-06 00:14:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f9sf6k4</td>\n",
       "      <td>e6q587</td>\n",
       "      <td>Populistless</td>\n",
       "      <td>1.575591e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>No you da ho!</td>\n",
       "      <td>2019-12-06 00:14:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id submission_id           user           utc  score  \\\n",
       "0    f9sfnw5        e6qdg8   leadchipmunk  1.575592e+09      1   \n",
       "1    f9sfrk9        e6qdg8  Noctis_Raptor  1.575592e+09      1   \n",
       "2    f9sfnu8        e6qcx9  Noctis_Raptor  1.575592e+09      1   \n",
       "3    f9sf6jl        e6q587        textoen  1.575591e+09      1   \n",
       "4    f9sf6k4        e6q587   Populistless  1.575591e+09      1   \n",
       "\n",
       "                                                body                date  \n",
       "0  Yo, who wants some popcorn? This is going to g... 2019-12-06 00:18:30  \n",
       "1                                        NERD FIGHT! 2019-12-06 00:19:25  \n",
       "2  To someone who can comfortably afford a Lambor... 2019-12-06 00:18:30  \n",
       "3  I thought it was short for Idunno? What shall ... 2019-12-06 00:14:05  \n",
       "4                                      No you da ho! 2019-12-06 00:14:05  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert utc to date\n",
    "submissions['date'] = submissions['utc'].apply(datetime.datetime.utcfromtimestamp)\n",
    "comments['date'] = comments['utc'].apply(datetime.datetime.utcfromtimestamp)\n",
    "#submissions.head()\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>user</th>\n",
       "      <th>utc</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>974</td>\n",
       "      <td>e2mek4</td>\n",
       "      <td>Lard_Baron</td>\n",
       "      <td>1.574887e+09</td>\n",
       "      <td>53</td>\n",
       "      <td>TIL of Joan of Leeds, an English nun, who, bor...</td>\n",
       "      <td></td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2019-11-27 20:40:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>973</td>\n",
       "      <td>e2mpwt</td>\n",
       "      <td>NobskaWoodsHole</td>\n",
       "      <td>1.574888e+09</td>\n",
       "      <td>35</td>\n",
       "      <td>TIL that both Mama Cass and Keith Moon died in...</td>\n",
       "      <td></td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2019-11-27 21:00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>972</td>\n",
       "      <td>e2msqp</td>\n",
       "      <td>ThatLocalPessimist</td>\n",
       "      <td>1.574889e+09</td>\n",
       "      <td>48335</td>\n",
       "      <td>Today I learned that Ringo Starr was the narra...</td>\n",
       "      <td></td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2019-11-27 21:05:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>971</td>\n",
       "      <td>e2mtlo</td>\n",
       "      <td>noooodlearms</td>\n",
       "      <td>1.574889e+09</td>\n",
       "      <td>1043</td>\n",
       "      <td>TIL: In 1995, an artist named William Utermohl...</td>\n",
       "      <td></td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2019-11-27 21:07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>970</td>\n",
       "      <td>e2mxse</td>\n",
       "      <td>Dota2Ethnography</td>\n",
       "      <td>1.574889e+09</td>\n",
       "      <td>237</td>\n",
       "      <td>TIL of El Mahrousa, the official presidential ...</td>\n",
       "      <td></td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2019-11-27 21:14:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index submission_id                user           utc  score  \\\n",
       "0    974        e2mek4          Lard_Baron  1.574887e+09     53   \n",
       "1    973        e2mpwt     NobskaWoodsHole  1.574888e+09     35   \n",
       "2    972        e2msqp  ThatLocalPessimist  1.574889e+09  48335   \n",
       "3    971        e2mtlo        noooodlearms  1.574889e+09   1043   \n",
       "4    970        e2mxse    Dota2Ethnography  1.574889e+09    237   \n",
       "\n",
       "                                               title body      subreddit  \\\n",
       "0  TIL of Joan of Leeds, an English nun, who, bor...       todayilearned   \n",
       "1  TIL that both Mama Cass and Keith Moon died in...       todayilearned   \n",
       "2  Today I learned that Ringo Starr was the narra...       todayilearned   \n",
       "3  TIL: In 1995, an artist named William Utermohl...       todayilearned   \n",
       "4  TIL of El Mahrousa, the official presidential ...       todayilearned   \n",
       "\n",
       "                 date  \n",
       "0 2019-11-27 20:40:08  \n",
       "1 2019-11-27 21:00:30  \n",
       "2 2019-11-27 21:05:37  \n",
       "3 2019-11-27 21:07:07  \n",
       "4 2019-11-27 21:14:45  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure time ordering of submissions\n",
    "submissions = submissions.sort_values(['date'], ascending = [1]).reset_index()\n",
    "submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank\n",
    "This uses [networkx](https://networkx.github.io/documentation/networkx-1.10/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # proff that directed edges are defined (start, end)\n",
    "# d = nx.DiGraph()\n",
    "# d.add_node(1)\n",
    "# d.add_node(2)\n",
    "# d.add_edge(1, 2)\n",
    "# nx.draw_networkx(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by creating a directed graph\n",
    "g = nx.DiGraph()\n",
    "\n",
    "# Each user is a node in the graph\n",
    "g.add_nodes_from(set(submissions['user'].append(comments['user'])))\n",
    "\n",
    "# Each comment is a directed edge\n",
    "pd.merge(submissions, comments, on='submission_id') \\\n",
    "    .apply(lambda row: g.add_edge(row[\"user_y\"], row[\"user_x\"]), axis=1)\n",
    "\n",
    "# Visualize the graph\n",
    "nx.draw(g)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets calculate pagerank\n",
    "pagerank = nx.pagerank(g)\n",
    "#pagerank # uncomment to preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and visualize it - 8000 is just a scaling factor to make the dots visible\n",
    "nx.draw(g, node_size=[8000 * x for x in pagerank.values()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by defining post content\n",
    "submissions['content'] = submissions['body'] + submissions['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper for calculating word frequencies\n",
    "def p_dist(content):\n",
    "    words = content.split() # tokenize by splitting on whitespace\n",
    "    counts = collections.Counter(words)\n",
    "    total = sum(counts.values())\n",
    "    return {word: count / total for word, count in counts.items()}\n",
    "\n",
    "# Calculate the word frequencies for every submission\n",
    "submissions['word_p_dist'] = submissions['content'].apply(p_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now calculating entropy is easy\n",
    "submissions['entropy'] = submissions['word_p_dist'].apply(lambda d: scipy.stats.entropy(list(d.values()), base=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A constant because 0 probabilities break math\n",
    "infinitesimal = 0.0001\n",
    "\n",
    "# Helper for calculating kld\n",
    "def kld(word_freq1, word_freq2):\n",
    "    if word_freq1 == None or word_freq2 == None:\n",
    "        return np.nan\n",
    "    p_dist1 = []\n",
    "    p_dist2 = []\n",
    "    for (word, freq) in word_freq1.items():\n",
    "        p_dist1.append(freq)\n",
    "        p_dist2.append(infinitesimal if not word in word_freq2 else word_freq2[word])\n",
    "    for (word, freq) in word_freq2.items():\n",
    "        if not word in word_freq1:\n",
    "            p_dist1.append(infinitesimal)\n",
    "            p_dist2.append(freq)\n",
    "    return scipy.stats.entropy(p_dist1, p_dist2, base=2)\n",
    "\n",
    "## simple test - should be equal\n",
    "# scipy.stats.entropy([0.25, 0.75, infinitesimal], [0.5, 0.4, 0.1], base=2)\n",
    "# kld({'a':0.25, 'b':0.75}, {'a':0.5, 'b':0.4, 'c':0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate novelty\n",
    "submissions['prev_submission_dist'] = submissions['word_p_dist'].shift(1).replace(to_replace={float(\"Nan\"): None})\n",
    "submissions['novelty'] = submissions.apply(lambda row: kld(row['word_p_dist'], row['prev_submission_dist']), axis=1)\n",
    "submissions = submissions.drop('prev_submission_dist', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And calculate transience\n",
    "submissions['next_submission_dist'] = submissions['word_p_dist'].shift(-1).replace(to_replace={float(\"Nan\"): None})\n",
    "submissions['transience'] = submissions.apply(lambda row: kld(row['word_p_dist'], row['next_submission_dist']), axis=1)\n",
    "submissions = submissions.drop('next_submission_dist', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate novelty based on multiple previous submissions\n",
    "window_size = 5\n",
    "\n",
    "# Helper to average kld of multiple other submissions\n",
    "def average_kld(of_dist, given_dists):\n",
    "    if any(map(lambda x: x == None, given_dists)):\n",
    "        return float(\"Nan\")\n",
    "    return np.mean(list(map(lambda given_dist: kld(of_dist, given_dist), given_dists)))\n",
    "\n",
    "# Get the distributions of earlier submissions\n",
    "submissions['prev_dists'] = submissions['word_p_dist'].apply(lambda x: list()) # get a sequence of empty lists\n",
    "for i in range(1, window_size + 1):\n",
    "    submissions['prev_dists'] = submissions['prev_dists'].combine(submissions['word_p_dist'].shift(i).replace(to_replace={float(\"Nan\"): None}), lambda x, y: x + [y])\n",
    "\n",
    "# And calculate novelty based on that window\n",
    "submissions['novelty_5'] = submissions.apply(lambda row: average_kld(row['word_p_dist'], row['prev_dists']), axis=1)\n",
    "\n",
    "# Cleanup\n",
    "submissions = submissions.drop('prev_dists', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distributions of later submissions\n",
    "submissions['next_dists'] = submissions['word_p_dist'].apply(lambda x: list()) # get a sequence of empty lists\n",
    "for i in range(1, window_size + 1):\n",
    "    submissions['next_dists'] = submissions['next_dists'].combine(submissions['word_p_dist'].shift(-1 * i).replace(to_replace={float(\"Nan\"): None}), lambda x, y: x + [y])\n",
    "\n",
    "# And calculate novelty based on that window\n",
    "submissions['transience_5'] = submissions.apply(lambda row: average_kld(row['word_p_dist'], row['next_dists']), axis=1)\n",
    "\n",
    "# Cleanup\n",
    "submissions = submissions.drop('next_dists', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the difference between novelty and transience - let's call this... the impact\n",
    "submissions['impact'] = submissions['novelty'] - submissions['transience']\n",
    "submissions['impact_5'] = submissions['novelty_5'] - submissions['transience_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping By Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_submissions = submissions.groupby(\"user\").apply(lambda g: pd.Series(\n",
    "    {\n",
    "        'num_posts': g['title'].size,\n",
    "        'max_score': g['score'].max(),\n",
    "        'mean_score': g['score'].mean(),\n",
    "        'min_score': g['score'].min(),\n",
    "        'mean_length': g.apply(lambda row: len(row['title'] + row['body']), axis=1).mean(),\n",
    "        'pagerank': pagerank[g['user'].iloc[0]], # weird indexing gets username and then finds pagerank for that user\n",
    "        'mean_impact': g['impact'].mean(),\n",
    "        'mean_novelty': g['novelty'].mean(),\n",
    "        'mean_transience': g['transience'].mean(),\n",
    "        'mean_impact_5': g['impact_5'].mean(),\n",
    "        'mean_novelty_5': g['novelty_5'].mean(),\n",
    "        'mean_transience_5': g['transience_5'].mean()\n",
    "    }\n",
    "))\n",
    "user_submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comments = comments.groupby(\"user\").apply(lambda g: pd.Series(\n",
    "    {\n",
    "        'num_comments': g['body'].size,\n",
    "        'max_score': g['score'].max(),\n",
    "        'mean_score': g['score'].mean(),\n",
    "        'min_score': g['score'].min(),\n",
    "        'mean_length': g['body'].apply(len).mean(),\n",
    "        'pagerank': pagerank[g['user'].iloc[0]] # weird indexing gets username and then finds pagerank for that user\n",
    "    }\n",
    "))\n",
    "user_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = user_submissions.join(user_comments, how=\"outer\", lsuffix=\"_submissions\", rsuffix=\"_comments\")\n",
    "\n",
    "## Clean up after the merge\n",
    "\n",
    "# outer join means pagerank may only be defined in one case and not the other - combine them\n",
    "users['pagerank'] = users.apply(lambda row: row['pagerank_comments'] if np.isnan(row['pagerank_submissions']) else row['pagerank_submissions'], axis=1)\n",
    "users = users.drop('pagerank_submissions', axis=1)\n",
    "users = users.drop('pagerank_comments', axis=1)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean score vs pagerank\n",
    "plt.scatter(x=users['pagerank'], y=users['mean_score_submissions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min score vs pagerank\n",
    "plt.scatter(x=users['pagerank'], y=users['min_score_submissions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max score vs pagerank\n",
    "plt.scatter(x=users['pagerank'], y=users['max_score_submissions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of comments vs pagerank\n",
    "plt.scatter(x=users['num_comments'], y=users['pagerank'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of posts vs pagerank - should be correlated (more submissions to comment on)\n",
    "plt.scatter(x=users['num_posts'], y=users['pagerank'])\n",
    "plt.show()\n",
    "# okay, my hypothesis was wrong..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users['mean_score_submissions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users['mean_score_comments'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users['max_score_submissions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users['max_score_comments'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users['min_score_submissions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users['min_score_comments'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=users['mean_length_submissions'], y=users['mean_score_submissions'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=users['mean_length_submissions'], y=users['pagerank'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Submission Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=submissions['novelty'], y=submissions['score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=submissions['transience'], y=submissions['score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novelty-transcience plot\n",
    "plt.scatter(x=submissions['novelty'], y=submissions['transience'], s=submissions['score'], alpha=0.3)\n",
    "\n",
    "# add line of equality\n",
    "domain = np.arange(0, 15)\n",
    "plt.plot(domain, domain, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=submissions['novelty_5'], y=submissions['score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=submissions['transience_5'], y=submissions['score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novelty-transcience plot\n",
    "plt.scatter(x=submissions['novelty_5'], y=submissions['transience_5'], s=submissions['score'], alpha=0.3)\n",
    "\n",
    "# add line of equality\n",
    "domain = np.arange(5, 15)\n",
    "plt.plot(domain, domain, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=submissions['impact'], y=submissions['score'], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users and KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=users['mean_impact'], y=users['mean_score_submissions'], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=users['mean_impact_5'], y=users['mean_score_submissions'], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novelty-transcience plot\n",
    "plt.scatter(x=users['mean_novelty'], y=users['mean_transience'], s=users['mean_score_submissions'], alpha=0.3)\n",
    "\n",
    "# add line of equality\n",
    "domain = np.arange(4, 15)\n",
    "plt.plot(domain, domain, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novelty-transcience plot\n",
    "plt.scatter(x=users['mean_novelty_5'], y=users['mean_transience_5'], s=users['mean_score_submissions'], alpha=0.3)\n",
    "\n",
    "# add line of equality\n",
    "domain = np.arange(4, 15)\n",
    "plt.plot(domain, domain, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pagerank and KLD for Users!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novelty-transcience plot\n",
    "plt.scatter(x=users['mean_novelty'], y=users['mean_transience'], s=users['pagerank']*6000, alpha=0.3)\n",
    "\n",
    "# add line of equality\n",
    "domain = np.arange(4, 15)\n",
    "plt.plot(domain, domain, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=users['mean_impact'], y=users['pagerank'], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# novelty-transcience plot\n",
    "plt.scatter(x=users['mean_novelty_5'], y=users['mean_transience_5'], s=users['pagerank']*7000, alpha=0.3)\n",
    "\n",
    "# add line of equality\n",
    "domain = np.arange(1, 8)\n",
    "plt.plot(domain, domain, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=users['mean_impact_5'], y=users['pagerank'], alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=users['mean_novelty_5'], y=users['pagerank'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
